# Техническое задание
## Система RAG Oozo - Интеллектуальный ассистент для работы с юридическими документами

---

## 1. ОБЩЕЕ ОПИСАНИЕ ПРОЕКТА

### 1.1. Назначение системы
RAG Oozo System - это полнофункциональная система Retrieval-Augmented Generation (RAG) для обработки юридических документов и генерации ответов на вопросы пользователей на основе индексированной документации. Система обеспечивает интеллектуальный поиск по документам и генерацию контекстных ответов с использованием технологий машинного обучения и векторного поиска.

### 1.2. Целевая аудитория
- Клиентские менеджеры компании
- Сотрудники, работающие с вопросами залогов
- Пользователи, нуждающиеся в быстром доступе к юридической документации

### 1.3. Основные требования
- Высокая точность поиска релевантной информации
- Поддержка русского языка
- Простой и интуитивный веб-интерфейс
- Масштабируемость и производительность
- Надежное логирование всех операций

---

## 2. ФУНКЦИОНАЛЬНЫЕ ТРЕБОВАНИЯ

### 2.1. Обработка документов

#### 2.1.1. Загрузка и обработка документов
**FR-001**: Система должна поддерживать загрузку документов в формате `.docx`

**Требования:**
- Автоматическое извлечение текста из документов Microsoft Word
- Поддержка нескольких документов одновременно
- Обработка различных кодировок и форматов текста
- Вычисление хэш-суммы файлов для отслеживания изменений
- Сохранение метаданных документов (название, путь, размер, дата изменения)

**Детали реализации:**
- Использование библиотеки `python-docx` для извлечения текста
- Вычисление SHA256 хэш-суммы для каждого файла
- Обработка ошибок при поврежденных файлах
- Логирование процесса обработки

#### 2.1.2. Разбиение документов на чанки
**FR-002**: Система должна автоматически разбивать документы на фрагменты (чанки) для оптимизации поиска

**Требования:**
- Размер чанка: 1000 символов (настраиваемый параметр)
- Перекрытие между чанками: 200 символов (настраиваемый параметр)
- Сохранение контекста при разбиении
- Глобальная нумерация чанков по всем документам

**Детали реализации:**
- Использование `RecursiveCharacterTextSplitter` из LangChain
- Разделители: `["\n\n", "\n", " ", ""]`
- Сохранение связей между чанками и исходными документами

#### 2.1.3. Индексация документов
**FR-003**: Система должна создавать векторные индексы для быстрого семантического поиска

**Требования:**
- Автоматическая индексация при первом запуске
- Переиндексация при обновлении документов
- Сохранение индекса на диск для последующего использования
- Обновление статусов чанков при переиндексации

**Детали реализации:**
- Использование FAISS для векторного индекса
- Генерация эмбеддингов с помощью multilingual-e5-large
- Сохранение индекса в директории `data/faiss_index/`
- Версионирование индексов через систему статусов (actual/stored)

### 2.2. Поиск и генерация ответов

#### 2.2.1. Обработка запросов пользователей
**FR-004**: Система должна обрабатывать текстовые запросы пользователей и генерировать релевантные ответы

**Требования:**
- Прием вопросов на русском языке
- Поиск наиболее релевантных фрагментов документов
- Генерация ответов на основе найденного контекста
- Возврат источников информации (чанков документов)

**Детали реализации:**
- Использование гибридного поиска (FAISS + BM25)
- Веса ретриверов: 50% BM25, 50% FAISS
- Отбор топ-5 наиболее релевантных чанков
- Формирование промпта для LLM с контекстом

#### 2.2.2. Гибридный поиск
**FR-005**: Система должна использовать комбинацию семантического и лексического поиска

**Требования:**
- Семантический поиск через векторные представления (FAISS)
- Лексический поиск через BM25 алгоритм
- Комбинирование результатов с весами 50/50
- Обеспечение высокой релевантности результатов

**Детали реализации:**
- `EnsembleRetriever` из LangChain
- `BM25Retriever` для лексического поиска
- `FAISS.as_retriever()` для векторного поиска

#### 2.2.3. Потоковая генерация ответов
**FR-006**: Система должна поддерживать потоковую генерацию ответов для улучшения UX

**Требования:**
- Отправка токенов ответа по мере генерации
- Использование Server-Sent Events (SSE)
- Отправка источников до начала генерации
- Обработка ошибок в потоковом режиме

**Детали реализации:**
- Эндпоинт `/api/query/stream` для потоковой генерации
- Использование `StreamingResponse` из FastAPI
- Формат SSE с событиями: `sources`, `token`, `done`, `error`

### 2.3. Пользовательский интерфейс

#### 2.3.1. Веб-интерфейс чата
**FR-007**: Система должна предоставлять веб-интерфейс для взаимодействия с пользователями

**Требования:**
- Современный и отзывчивый дизайн
- Интерфейс чата с историей сообщений
- Поле ввода с поддержкой многострочного текста
- Индикатор загрузки при обработке запроса
- Отображение источников информации

**Детали реализации:**
- React приложение с компонентной архитектурой
- Компоненты: `ChatInterface`, `MessageList`, `MessageInput`, `Message`
- CSS стилизация для современного UI
- Автоматическая прокрутка к новым сообщениям

#### 2.3.2. Приветственное сообщение
**FR-008**: При первом входе пользователь должен видеть приветственное сообщение

**Требования:**
- Информация о назначении системы
- Контактная информация для обращений
- Автоматическое скрытие при отправке первого сообщения

### 2.4. Логирование и мониторинг

#### 2.4.1. Логирование запросов и ответов
**FR-009**: Система должна логировать все запросы пользователей и ответы системы

**Требования:**
- Сохранение вопроса пользователя
- Сохранение ответа системы
- Сохранение времени обработки
- Сохранение IP-адреса и логина пользователя
- Сохранение финального промпта, отправленного в LLM
- Связывание запросов с использованными чанками

**Детали реализации:**
- Таблица `query_logs` в PostgreSQL
- Таблица `chunks` для хранения чанков
- Промежуточная таблица `query_log_chunks` для связи many-to-many
- Схема БД: `oozo-schema`

#### 2.4.2. Статистика системы
**FR-010**: Система должна предоставлять статистику о состоянии индекса

**Требования:**
- Количество проиндексированных документов
- Количество чанков в индексе
- Размер индекса в мегабайтах
- Дата последнего обновления индекса

### 2.5. API эндпоинты

#### 2.5.1. Основные эндпоинты
**FR-011**: Система должна предоставлять REST API для всех операций

**Эндпоинты:**
- `POST /api/query` - Обработка запроса пользователя
- `POST /api/query/stream` - Потоковая генерация ответа
- `GET /api/query/stream` - Потоковая генерация через GET
- `GET /health` - Проверка состояния системы
- `GET /api/info` - Информация о системе
- `GET /api/stats` - Статистика коллекции документов
- `POST /api/similarity` - Поиск похожих документов
- `POST /api/ingest` - Переиндексация документов
- `GET /api/documents` - Список доступных документов
- `GET /api/logs` - Получение логов запросов
- `DELETE /api/logs` - Очистка логов

---

## 3. ТЕХНИЧЕСКИЕ ТРЕБОВАНИЯ

### 3.1. Архитектура системы

#### 3.1.1. Общая архитектура
**TR-001**: Система должна быть построена по модульной архитектуре с четким разделением слоев

**Компоненты:**
1. **Presentation Layer (Слой представления)**
   - React Frontend
   - API Documentation (Swagger)

2. **API Layer (Слой API)**
   - FastAPI приложение
   - CORS middleware
   - Валидация данных (Pydantic)

3. **Business Logic Layer (Слой бизнес-логики)**
   - RAG System
   - Document Processor
   - Vector Store Manager

4. **Data Layer (Слой данных)**
   - PostgreSQL база данных
   - FAISS векторный индекс
   - Файловое хранилище документов

5. **External Services (Внешние сервисы)**
   - LLM API (ModelRun Inference Cloud)
   - HuggingFace Embeddings

#### 3.1.2. Технологический стек

**Backend:**
- Python 3.9+
- FastAPI 0.104+
- SQLAlchemy 2.0+
- LangChain 0.1+
- FAISS 1.7+
- PostgreSQL 15+
- HuggingFace Transformers

**Frontend:**
- React 18+
- JavaScript ES6+
- CSS3

**Инфраструктура:**
- Docker & Docker Compose
- NVIDIA Runtime (для GPU поддержки)

### 3.2. База данных

#### 3.2.1. Схема базы данных
**TR-002**: Система должна использовать PostgreSQL с определенной схемой

**Схема:** `oozo-schema`

**Таблицы:**

1. **chunks** - Хранение чанков документов
   - `id` (SERIAL PRIMARY KEY)
   - `content` (TEXT NOT NULL)
   - `document_title` (VARCHAR(500))
   - `file_path` (VARCHAR(1000))
   - `file_hash` (VARCHAR(64))
   - `chunk_index` (INTEGER)
   - `total_chunks` (INTEGER)
   - `status` (VARCHAR(50) DEFAULT 'actual')
   - `metadata_json` (TEXT)
   - `created_at` (TIMESTAMP)

2. **query_logs** - Логирование запросов
   - `id` (SERIAL PRIMARY KEY)
   - `user_login` (VARCHAR(255))
   - `user_ip` (VARCHAR(45))
   - `question` (TEXT NOT NULL)
   - `final_prompt` (TEXT)
   - `answer` (TEXT)
   - `processing_time` (VARCHAR(50))
   - `error_message` (TEXT)
   - `status` (VARCHAR(50) DEFAULT 'success')
   - `created_at` (TIMESTAMP)

3. **query_log_chunks** - Связь many-to-many
   - `query_log_id` (INTEGER)
   - `chunk_id` (INTEGER)
   - PRIMARY KEY (query_log_id, chunk_id)

**Индексы:**
- `idx_chunks_file_hash` на `chunks.file_hash`
- `idx_chunks_status` на `chunks.status`
- `idx_query_logs_user_login` на `query_logs.user_login`
- `idx_query_logs_user_ip` на `query_logs.user_ip`

#### 3.2.2. Миграции
**TR-003**: Система должна поддерживать миграции базы данных

**Требования:**
- SQL-скрипты миграций в директории `backend/migrations/`
- Автоматическое применение миграций при инициализации
- Версионирование схемы базы данных

### 3.3. Векторный поиск

#### 3.3.1. Модель эмбеддингов
**TR-004**: Система должна использовать multilingual-e5-large для генерации эмбеддингов

**Требования:**
- Модель: `intfloat/multilingual-e5-large`
- Размерность векторов: 1024
- Нормализация векторов: включена
- Поддержка русского языка

#### 3.3.2. Векторное хранилище
**TR-005**: Система должна использовать FAISS для векторного поиска

**Требования:**
- Индексация векторов документов
- Быстрый поиск похожих векторов (similarity search)
- Сохранение индекса на диск
- Загрузка индекса при старте приложения

**Детали реализации:**
- Использование `FAISS.from_documents()` для создания индекса
- Метод `similarity_search_with_score()` для поиска
- Сохранение в формате: `index.faiss` и `index.pkl`

### 3.4. Генерация ответов

#### 3.4.1. Языковая модель
**TR-006**: Система должна использовать LLM для генерации ответов

**Требования:**
- Использование API ModelRun Inference Cloud
- Модель: `model-run-vekow-trunk`
- Поддержка потоковой генерации
- Настройка температуры: 0.1
- Timeout: 600 секунд

#### 3.4.2. Промпт-инжиниринг
**TR-007**: Система должна использовать оптимизированные промпты для генерации ответов

**Требования:**
- Промпт для юридических вопросов
- Инструкции по использованию контекста
- Требования к формату ответа
- Ограничения на выдумывание информации

### 3.5. Конфигурация

#### 3.5.1. Переменные окружения
**TR-008**: Система должна настраиваться через переменные окружения

**Основные переменные:**
- `OPENAI_API_KEY` - API ключ (обязательно)
- `EMBEDDING_MODEL_NAME` - Модель эмбеддингов
- `DOCS_PATH` - Путь к документам
- `INDEX_PATH` - Путь к векторному индексу
- `CHUNK_SIZE` - Размер чанка (по умолчанию: 1000)
- `CHUNK_OVERLAP` - Перекрытие чанков (по умолчанию: 200)
- `POSTGRES_DB` - Имя базы данных
- `POSTGRES_USER` - Пользователь БД
- `POSTGRES_PASSWORD` - Пароль БД
- `POSTGRES_HOST` - Хост БД
- `POSTGRES_PORT` - Порт БД

### 3.6. Развертывание

#### 3.6.1. Docker контейнеризация
**TR-009**: Система должна развертываться через Docker Compose

**Сервисы:**
1. **postgres** - База данных PostgreSQL
   - Образ: `postgres:15-alpine`
   - Порт: 5432
   - Тома: `postgres-data`

2. **rag-app** - Backend приложение
   - Сборка из `./backend/Dockerfile`
   - Порт: 8000
   - Runtime: nvidia (для GPU поддержки)
   - Тома: логи, документы, модели, индекс

3. **frontend** - Frontend приложение
   - Сборка из `./frontend/Dockerfile`
   - Порт: 3000
   - Тома: исходный код

#### 3.6.2. Health checks
**TR-010**: Каждый сервис должен иметь health check

**Требования:**
- Проверка доступности сервиса
- Автоматический перезапуск при сбоях
- Зависимости между сервисами

---

## 4. НЕФУНКЦИОНАЛЬНЫЕ ТРЕБОВАНИЯ

### 4.1. Производительность

#### 4.1.1. Время ответа
**NFR-001**: Время генерации ответа должно быть менее 3 секунд для типичных запросов

**Метрики:**
- Время поиска релевантных чанков: < 500ms
- Время генерации ответа LLM: < 2.5s
- Общее время обработки: < 3s

#### 4.1.2. Пропускная способность
**NFR-002**: Система должна обрабатывать не менее 50 одновременных запросов

**Требования:**
- Поддержка асинхронной обработки
- Оптимизация использования ресурсов
- Масштабирование при необходимости

#### 4.1.3. Использование ресурсов
**NFR-003**: Система должна эффективно использовать ресурсы сервера

**Требования:**
- Память: ~4GB для типичной установки
- CPU: эффективное использование многоядерности
- Диск: оптимизация размера индекса

### 4.2. Надежность

#### 4.2.1. Обработка ошибок
**NFR-004**: Система должна корректно обрабатывать все типы ошибок

**Требования:**
- Graceful degradation при недоступности внешних сервисов
- Информативные сообщения об ошибках
- Логирование всех ошибок
- Автоматическое восстановление при сбоях

#### 4.2.2. Отказоустойчивость
**NFR-005**: Система должна продолжать работу при частичных сбоях

**Требования:**
- Защита от падения при ошибках индексации
- Обработка невалидных документов
- Резервные механизмы для критических операций

### 4.3. Безопасность

#### 4.3.1. Валидация входных данных
**NFR-006**: Все входные данные должны быть валидированы

**Требования:**
- Валидация через Pydantic схемы
- Проверка типов и ограничений
- Санитизация пользовательского ввода
- Защита от инъекций

#### 4.3.2. Логирование безопасности
**NFR-007**: Система должна логировать действия пользователей

**Требования:**
- Сохранение IP-адресов пользователей
- Сохранение логинов пользователей
- Аудит всех запросов
- Возможность отслеживания действий

### 4.4. Масштабируемость

#### 4.4.1. Горизонтальное масштабирование
**NFR-008**: Система должна поддерживать горизонтальное масштабирование

**Требования:**
- Возможность запуска нескольких экземпляров backend
- Разделение состояния между инстансами
- Балансировка нагрузки

#### 4.4.2. Масштабирование данных
**NFR-009**: Система должна эффективно работать с большими объемами данных

**Требования:**
- Поддержка тысяч документов
- Эффективная индексация больших коллекций
- Оптимизация поиска при росте данных

### 4.5. Удобство использования

#### 4.5.1. Пользовательский интерфейс
**NFR-010**: Интерфейс должен быть интуитивно понятным

**Требования:**
- Простой и понятный дизайн
- Быстрая загрузка страницы
- Отзывчивость на действия пользователя
- Понятные сообщения об ошибках

#### 4.5.2. Документация
**NFR-011**: Система должна иметь полную документацию

**Требования:**
- API документация (Swagger/OpenAPI)
- Инструкции по развертыванию
- Руководство пользователя
- Техническая документация

---

## 5. ТРЕБОВАНИЯ К ДАННЫМ

### 5.1. Формат документов

#### 5.1.1. Поддерживаемые форматы
**DR-001**: Система должна поддерживать документы в формате `.docx`

**Требования:**
- Microsoft Word 2007+ формат
- Поддержка русского текста
- Обработка различных кодировок
- Максимальный размер файла: 100MB

### 5.2. Структура данных

#### 5.2.1. Метаданные документов
**DR-002**: Каждый документ должен иметь метаданные

**Обязательные поля:**
- Название документа
- Путь к файлу
- Размер файла
- Хэш-сумма файла (SHA256)

**Опциональные поля:**
- Дата создания
- Дата модификации
- Дополнительные метаданные в JSON формате

#### 5.2.2. Структура чанков
**DR-003**: Каждый чанк должен содержать необходимую информацию

**Обязательные поля:**
- Содержимое (текст чанка)
- Глобальный индекс чанка
- Общее количество чанков
- Статус (actual/stored)

**Связанные данные:**
- Ссылка на исходный документ
- Метаданные документа

---

## 6. ИНТЕРФЕЙСЫ И ИНТЕГРАЦИИ

### 6.1. REST API

#### 6.1.1. Формат запросов и ответов
**IR-001**: API должно использовать JSON формат

**Требования:**
- Content-Type: `application/json`
- UTF-8 кодировка
- Валидация через Pydantic схемы

#### 6.1.2. Аутентификация
**IR-002**: API должно поддерживать базовую аутентификацию (опционально)

**Примечание:** В текущей версии аутентификация не реализована, но предусмотрена возможность добавления через заголовки.

### 6.2. Внешние сервисы

#### 6.2.1. LLM API
**IR-003**: Интеграция с ModelRun Inference Cloud

**Требования:**
- Endpoint: `https://*.modelrun.inference.cloud.ru/v1`
- Формат: OpenAI-compatible API
- Поддержка streaming
- Timeout: 600 секунд

#### 6.2.2. Embeddings
**IR-004**: Использование HuggingFace моделей

**Требования:**
- Локальное хранение модели
- Кэширование эмбеддингов
- Оптимизация памяти

---

## 7. ТРЕБОВАНИЯ К ТЕСТИРОВАНИЮ

### 7.1. Типы тестов

#### 7.1.1. Модульные тесты
**TR-011**: Критические компоненты должны иметь модульные тесты

**Требования:**
- Покрытие основных функций обработки документов
- Тестирование логики разбиения на чанки
- Тестирование работы с базой данных

#### 7.1.2. Интеграционные тесты
**TR-012**: Система должна иметь интеграционные тесты

**Требования:**
- Тестирование API эндпоинтов
- Тестирование работы RAG системы
- Тестирование миграций БД

### 7.2. Тестовые данные

#### 7.2.1. Тестовые документы
**TR-013**: Должны быть подготовлены тестовые документы

**Требования:**
- Различные типы юридических документов
- Различные размеры документов
- Примеры для проверки поиска

---

## 8. ТРЕБОВАНИЯ К ДОКУМЕНТАЦИИ

### 8.1. Техническая документация

#### 8.1.1. Документация API
**DR-004**: Должна быть автоматическая документация API

**Требования:**
- Swagger UI на `/docs`
- Описание всех эндпоинтов
- Примеры запросов и ответов
- Описание схем данных

#### 8.1.2. Архитектурная документация
**DR-005**: Должна быть документация по архитектуре системы

**Требования:**
- Описание компонентов системы
- Диаграммы потоков данных
- Описание взаимодействия компонентов

### 8.2. Пользовательская документация

#### 8.2.1. Руководство пользователя
**DR-006**: Должно быть руководство для конечных пользователей

**Требования:**
- Инструкции по использованию интерфейса
- Примеры вопросов
- Раздел FAQ

#### 8.2.2. Руководство администратора
**DR-007**: Должно быть руководство для администраторов

**Требования:**
- Инструкции по развертыванию
- Настройка системы
- Устранение неполадок
- Мониторинг системы

---

## 9. ПЛАН РАЗВИТИЯ

### 9.1. Текущая версия (v1.0.0)

**Реализованные функции:**
- ✅ Обработка документов .docx
- ✅ Векторный поиск через FAISS
- ✅ Гибридный поиск (FAISS + BM25)
- ✅ Генерация ответов через LLM
- ✅ Потоковая генерация ответов
- ✅ Веб-интерфейс на React
- ✅ Логирование в PostgreSQL
- ✅ REST API
- ✅ Docker развертывание

### 9.2. Планируемые улучшения

**Версия 1.1.0:**
- Поддержка PDF документов
- Улучшение промптов
- Кэширование ответов
- Метрики производительности

**Версия 1.2.0:**
- Аутентификация пользователей
- Роли и права доступа
- Экспорт логов
- Аналитика использования

**Версия 2.0.0:**
- Мультитенантность
- Плагины для различных типов документов
- WebSocket поддержка
- Улучшенная система поиска

---

## 10. ГЛОССАРИЙ

**RAG** - Retrieval-Augmented Generation, подход к генерации текста с использованием поиска по документам

**FAISS** - Facebook AI Similarity Search, библиотека для эффективного векторного поиска

**Чанк** - Фрагмент документа, полученный в результате разбиения исходного документа

**Эмбеддинг** - Векторное представление текста в многомерном пространстве

**LLM** - Large Language Model, большая языковая модель

**BM25** - Best Matching 25, алгоритм ранжирования документов по релевантности

**Ensemble Retriever** - Гибридный ретривер, комбинирующий результаты нескольких методов поиска

**SSE** - Server-Sent Events, технология для потоковой передачи данных от сервера к клиенту

---

## 11. ПРИЛОЖЕНИЯ

### 11.1. Диаграммы архитектуры

Диаграммы архитектуры системы описаны в документе `ARCHITECTURE.md`.

### 11.2. Примеры использования

Примеры использования API описаны в документах:
- `QUICKSTART.md` - Быстрый старт
- `DEVELOPMENT.md` - Разработка
- `DEPLOYMENT.md` - Развертывание

### 11.3. Схемы базы данных

Схема базы данных описана в файле `backend/migrations/init_schema.sql`.

---

**Версия документа:** 1.0.0  
**Дата создания:** 2024  
**Автор:** Команда разработки RAG Oozo System

---

*Это техническое задание является живым документом и может обновляться по мере развития проекта.*

