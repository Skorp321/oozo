import os
import requests
from openai import OpenAI
import subprocess


api_key = 'dummy_key'
url = "https://565df812-6798-4e3d-9a62-18d67e029d53.modelrun.inference.cloud.ru/v1"
model_name = "model-run-vekow-trunk"


def check_vllm_instance(base_url: str, model_name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–Ω—Å—Ç–∞–Ω—Å–∞ vLLM –∏ –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
    
    Args:
        base_url: –ë–∞–∑–æ–≤—ã–π URL API (–Ω–∞–ø—Ä–∏–º–µ—Ä, https://.../v1)
        model_name: –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        True –µ—Å–ª–∏ –∏–Ω—Å—Ç–∞–Ω—Å –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞, False –∏–Ω–∞—á–µ
    """
    print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏–Ω—Å—Ç–∞–Ω—Å–∞ vLLM...")
    print(f"   URL: {base_url}")
    print(f"   –ú–æ–¥–µ–ª—å: {model_name}\n")
    
    health = base_url + "/health"
    subprocess.run(["curl", "-X", "GET", health], check=True)
    
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∞–∑–æ–≤–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞
    try:
        print("1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∞–∑–æ–≤–æ–≥–æ URL...")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º /models —ç–Ω–¥–ø–æ–∏–Ω—Ç
        models_url = f"{base_url}/models"
        response = requests.get(models_url, timeout=10)
        print("--- Status code: ", response.status_code)
        response = requests.get(models_url, timeout=10)
        response.raise_for_status()
        print(f"   ‚úÖ –ë–∞–∑–æ–≤—ã–π URL –¥–æ—Å—Ç—É–ø–µ–Ω (—Å—Ç–∞—Ç—É—Å: {response.status_code})")
    except requests.exceptions.RequestException as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –±–∞–∑–æ–≤–æ–º—É URL: {e}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    try:
        print("\n2Ô∏è‚É£ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        models_data = response.json()
        
        if "data" in models_data:
            available_models = [model["id"] for model in models_data["data"]]
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(available_models)}")
            for model in available_models:
                print(f"      - {model}")
        else:
            print(f"   ‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {models_data}")
            available_models = []
    except (KeyError, ValueError) as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –ù–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω–æ–π –º–æ–¥–µ–ª–∏
    print(f"\n3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ '{model_name}'...")
    if model_name in available_models:
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å '{model_name}' –Ω–∞–π–¥–µ–Ω–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω–∞")
        model_found = True
    else:
        print(f"   ‚ö†Ô∏è –ú–æ–¥–µ–ª—å '{model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ")
        print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(available_models)}")
        model_found = False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 4: –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç
    print(f"\n4Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        test_response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç"}],
            max_tokens=10,
            timeout=30
        )
        print(f"   ‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω")
        print(f"   –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {test_response.choices[0].message.content[:50]}...")
        return True
    except Exception as e:
        if model_found:
            print(f"   ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ—à–µ–ª: {e}")
        else:
            print(f"   ‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ—à–µ–ª: {e}")
        return False


# –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
if __name__ == "__main__":
    print("=" * 70)
    is_available = check_vllm_instance(url, model_name)
    print("\n" + "=" * 70)
    
    if is_available:
        print("\n‚úÖ –ò–ù–°–¢–ê–ù–° –†–ê–ë–û–¢–ê–ï–¢ –ò –ì–û–¢–û–í –ö –ó–ê–ü–†–û–°–ê–ú\n")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å
        print("üì§ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...")
        client = OpenAI(api_key=api_key, base_url=url)
        
        response = client.chat.completions.create(
            model=model_name,
            max_tokens=5000,
            temperature=0.5,
            presence_penalty=0,
            messages=[
                {
                    "role": "user",
                    "content": "–ö–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å —Ö–æ—Ä–æ—à–∏–π –∫–æ–¥?"
                }
            ]
        )
        
        print("\nüì• –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
        print("-" * 70)
        print(response.choices[0].message.content)
        print("-" * 70)
    else:
        print("\n‚ùå –ò–ù–°–¢–ê–ù–° –ù–ï –î–û–°–¢–£–ü–ï–ù –ò–õ–ò –ú–û–î–ï–õ–¨ –ù–ï –ù–ê–ô–î–ï–ù–ê")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("   1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å URL")
        print("   2. –ó–∞–ø—É—â–µ–Ω –ª–∏ –∏–Ω—Å—Ç–∞–Ω—Å")
        print("   3. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏")