services:
  # Backend RAG System
  rag-app:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: rag-backend
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME:-/app/models/multilingual-e5-large}
      - DOCS_PATH=/app/docs
      - INDEX_PATH=/app/data/faiss_index
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-200}
      - OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME:-gpt-3.5-turbo}
      - MAX_TOKENS=${MAX_TOKENS:-4000}
      - TEMPERATURE=${TEMPERATURE:-0.7}
    volumes:
      - ./docs:/app/docs:ro
      - ./backend/models/multilingual-e5-large:/app/models/multilingual-e5-large
      - faiss-index-data:/app/data/faiss_index
    networks:
      - rag-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 60s

  # Frontend React App
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: rag-frontend
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://rag-app:8000
      - REACT_APP_ENVIRONMENT=production
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    networks:
      - rag-network
    depends_on:
      rag-app:
        condition: service_healthy
    restart: unless-stopped

  # Gradio Frontend
  gradio-frontend:
    build:
      context: ./gradio_frontend
      dockerfile: Dockerfile
    container_name: rag-gradio
    ports:
      - "7861:7860"
    environment:
      - API_BASE_URL=http://rag-backend:8000
    networks:
      - rag-network
    restart: unless-stopped

networks:
  rag-network:
    driver: bridge

volumes:
  faiss-index-data: 